{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaf0c76-2490-45e0-89a9-d49ba3a1ce99",
   "metadata": {},
   "source": [
    "# Autonomous Driving - Car Detection\n",
    "\n",
    "We will be using YOLO Algorithm to detect Objects\n",
    "\n",
    "**What to expect in this project**:\n",
    "\n",
    "- Detect objects in a car detection dataset\n",
    "- Implement non-max suppression to increase accuracy\n",
    "- Implement intersection over union\n",
    "- Handle bounding boxes, a type of image annotation popular in deep learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5660f6-a284-4922-bbba-029ccf06ff6d",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Packages\n",
    "\n",
    "Loading the packages and dependencies that will come in handy as you build the object detector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1811730c-9180-4199-92a3-fde05ee83052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from yad2k.models.keras_yolo import yolo_head\n",
    "from yad2k.utils.utils import draw_boxes, get_colors_for_classes, scale_boxes, read_classes, read_anchors, preprocess_image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e30587-2d2d-428f-a969-38b49bc2194e",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Problem Statement\n",
    "\n",
    "We are working on a self-driving car.As a critical component of this project, we'd like to first build a car detection system. To collect data, we supposed and have mounted a camera to the hood (meaning the front) of the car, which takes pictures of the road ahead every few seconds as you drive around. \n",
    "\n",
    "<center>\n",
    "<video width=\"400\" height=\"200\" src=\"nb_images/road_video_compressed2.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "<caption><center> Pictures taken from a car-mounted camera while driving around Silicon Valley. <br> Dataset provided by <a href=\"https://www.drive.ai/\">drive.ai</a>.\n",
    "</center></caption>\n",
    "\n",
    "You've gathered all these images into a folder and labelled them by drawing bounding boxes around every car you found. Here's an example of what your bounding boxes look like:\n",
    " \n",
    "\n",
    "in this project we will explain how YOLO performs object detection, and then apply it to car detection. Because the YOLO model is very computationally expensive to train, the pre-trained weights are already loaded !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310045b-81df-4932-be67-966cd404a007",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b31b6a-32f5-4de1-ae0e-5caaf76b1be6",
   "metadata": {},
   "source": [
    "\"You Only Look Once\" (YOLO) is a popular algorithm because it achieves high accuracy while also being able to run in real time. This algorithm \"only looks once\" at the image in the sense that it requires only one forward propagation pass through the network to make predictions. After non-max suppression, it then outputs recognized objects together with the bounding boxes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d1f57-7acd-4374-9593-e2c6f3bf9230",
   "metadata": {},
   "source": [
    "###  - yolo_filter_boxes\n",
    "\n",
    "Implement `yolo_filter_boxes()`.\n",
    "1. Compute box scores by doing the elementwise produc ($p \\times c$).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a31631-2cf4-4c84-99bb-8584c809ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(boxes,box_confidence,box_class_probs,threshold=0.6):\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_classes = tf.math.argmax(box_scores,axis=-1)\n",
    "    box_classes_scores = tf.math.reduce_max(box_scores,axis=-1)\n",
    "    filtering_mask = box_classes_scores >= threshold\n",
    "    scores = tf.boolean_mask(box_classes_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    return scores,boxes,classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e43db-acfa-41ee-8be4-a6a993fe1393",
   "metadata": {},
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3 - Non-max Suppression\n",
    "\n",
    "Even after filtering by thresholding over the class scores, you still end up with a lot of overlapping boxes. A second filter for selecting the right boxes is called non-maximum suppression (NMS). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e01bc3-fc1b-4804-b674-f306d35d537a",
   "metadata": {},
   "source": [
    "<img src=\"nb_images/non-max-suppression.png\" style=\"width:500px;height:400;\">\n",
    "<caption><center> <u>  </u> In this example, the model has predicted 3 cars, but it's actually 3 predictions of the same car. Running non-max suppression (NMS) will select only the most accurate (highest probability) of the 3 boxes. <br> </center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202901e3-2a6b-46a8-9ae2-22224114f60f",
   "metadata": {},
   "source": [
    "- IOU\n",
    "\n",
    "Implement `iou()` \n",
    "Intersection over union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fc97b1-f8a3-4997-915e-bb23777155f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1,box2):\n",
    "    (box1_x1,box1_y1,box1_x2,box1_y2) = box1\n",
    "    (box2_x1,box2_y1,box2_x2,box2_y2) = box2\n",
    "    xi1 = max(box1_x1,box2_x1)\n",
    "    yi1 = max(box1_y1,box2_y1)\n",
    "    xi2 = min(box1_x2,box2_x2)\n",
    "    yi2 = min(box1_y2,box2_y2)\n",
    "    inter_height = max(0,yi2-yi1)\n",
    "    inter_width = max(0, xi2 - xi1)\n",
    "    inter_area = inter_width * inter_height\n",
    "    box1_area = (box1_y2-box1_y1) * (box1_x2 - box1_x1)\n",
    "    box2_area = (box2_y2 - box2_y1) * (box2_x2 - box2_x1)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f4dc1-f398-4d44-ad06-5941bab7e478",
   "metadata": {},
   "source": [
    "### 3 - yolo_non_max_suppression\n",
    "\n",
    "Implement `yolo_non_max_suppression()` using TensorFlow. TensorFlow has two built-in functions that are used to implement non-max suppression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d878b6-7820-4670-8b20-2895e873c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores,boxes,classes,max_boxes =10, iou_threshold=0.5):\n",
    "    max_box_tensor = tf.Variable(max_boxes, dtype=\"int32\")\n",
    "    nms_indices = tf.image.non_max_suppression(boxes,scores,max_box_tensor,iou_threshold)\n",
    "    scores = tf.gather(scores, nms_indices)\n",
    "    boxes = tf.gather(boxes, nms_indices)\n",
    "    classes = tf.gather(classes,nms_indices)\n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6131f6ba-952b-4bce-bd39-2c61376595f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return tf.keras.backend.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabfc642-3c1a-4f16-8e8a-ece0cbe037eb",
   "metadata": {},
   "source": [
    "<a name='2-5'></a>\n",
    "### 2.5 - Wrapping Up the Filtering\n",
    "\n",
    "It's time to implement a function taking the output of the deep CNN (the 19x19x5x85 dimensional encoding) and filtering through all the boxes using the functions we've just implemented. \n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### 4 - yolo_eval\n",
    "\n",
    "Implement `yolo_eval()` which takes the output of the YOLO encoding and filters the boxes using score threshold and NMS. There's just one last implementational detail to know. There're a few ways of representing boxes, such as via their corners or via their midpoint and height/width. YOLO converts between a few such formats at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a513b5-2540-47ac-b011-83ecfafea6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape=(720,1280), max_boxes=10,score_threshold=0.6,iou_threshold=0.5):\n",
    "    box_xy, box_wh,box_confidence,box_class_probs = yolo_outputs\n",
    "    boxes = yolo_boxes_to_corners(box_xy,box_wh)\n",
    "    scores,boxes,classes = yolo_filter_boxes(boxes,box_confidence,box_class_probs,score_threshold)\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores,boxes,classes,max_boxes,iou_threshold)\n",
    "    return scores,boxes,classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de45b448-7b0f-4c19-b115-c6e5a5814315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "model_image_size = (608, 608) # Same as yolo_model input layer size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced52a2e-b68f-408d-a89f-222e382ee3c6",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3- Loading a Pre-trained Model\n",
    "\n",
    "Training a YOLO model takes a very long time and requires a fairly large dataset of labelled bounding boxes for a large range of target classes. We are going to load an existing pre-trained Keras YOLO model stored in \"yolo.h5\". These weights come from the official YOLO website, and were converted using a function written by Allan Zelener.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0cc2fc-22df-41d3-ba78-5136e60e9626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(\"model_data/\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393cbd52-4849-461f-b2c8-d7dc39f629bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 608, 608, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 608, 608, 32)         864       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 608, 608, 32)         128       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 608, 608, 32)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 304, 304, 32)         0         ['leaky_re_lu[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 304, 304, 64)         18432     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 304, 304, 64)         256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 304, 304, 64)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 152, 152, 64)         0         ['leaky_re_lu_1[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 152, 152, 128)        73728     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 152, 152, 128)        512       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 152, 152, 128)        0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 152, 152, 64)         8192      ['leaky_re_lu_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 152, 152, 64)         256       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 152, 152, 64)         0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 152, 152, 128)        73728     ['leaky_re_lu_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 152, 152, 128)        512       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 152, 152, 128)        0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 76, 76, 128)          0         ['leaky_re_lu_4[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 76, 76, 256)          294912    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 76, 76, 256)          1024      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 76, 76, 256)          0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 76, 76, 128)          32768     ['leaky_re_lu_5[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 76, 76, 128)          512       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 76, 76, 128)          0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 76, 76, 256)          294912    ['leaky_re_lu_6[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 76, 76, 256)          1024      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 76, 76, 256)          0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 38, 38, 256)          0         ['leaky_re_lu_7[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 38, 38, 512)          1179648   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 38, 38, 512)          2048      ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 38, 38, 512)          0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 38, 38, 256)          131072    ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 38, 38, 256)          1024      ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 38, 38, 256)          0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 38, 38, 512)          1179648   ['leaky_re_lu_9[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 38, 38, 512)          2048      ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 38, 38, 512)          0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 38, 38, 256)          131072    ['leaky_re_lu_10[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 38, 38, 256)          1024      ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 38, 38, 256)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 38, 38, 512)          1179648   ['leaky_re_lu_11[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 38, 38, 512)          2048      ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 38, 38, 512)          0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 19, 19, 512)          0         ['leaky_re_lu_12[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 19, 19, 1024)         4718592   ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 19, 19, 1024)         4096      ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 19, 19, 1024)         0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 19, 19, 512)          524288    ['leaky_re_lu_13[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 19, 19, 512)          2048      ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 19, 19, 512)          0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 19, 19, 1024)         4718592   ['leaky_re_lu_14[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 19, 19, 1024)         4096      ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 19, 19, 1024)         0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 19, 19, 512)          524288    ['leaky_re_lu_15[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 19, 19, 512)          2048      ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 19, 19, 512)          0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 19, 19, 1024)         4718592   ['leaky_re_lu_16[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 19, 19, 1024)         4096      ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 19, 19, 1024)         0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 19, 19, 1024)         9437184   ['leaky_re_lu_17[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 19, 19, 1024)         4096      ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 38, 38, 64)           32768     ['leaky_re_lu_12[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 19, 19, 1024)         0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 38, 38, 64)           256       ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 19, 19, 1024)         9437184   ['leaky_re_lu_18[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 38, 38, 64)           0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 19, 19, 1024)         4096      ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " space_to_depth_x2 (Lambda)  (None, 19, 19, 256)          0         ['leaky_re_lu_20[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 19, 19, 1024)         0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 19, 19, 1280)         0         ['space_to_depth_x2[0][0]',   \n",
      "                                                                     'leaky_re_lu_19[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 19, 19, 1024)         1179648   ['concatenate[0][0]']         \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 19, 19, 1024)         4096      ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 19, 19, 1024)         0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 19, 19, 425)          435625    ['leaky_re_lu_21[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50983561 (194.49 MB)\n",
      "Trainable params: 50962889 (194.41 MB)\n",
      "Non-trainable params: 20672 (80.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7fc5aa-329d-472e-8e96-3cb624afc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_file):\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "    \n",
    "    yolo_model_outputs = yolo_model(image_data)\n",
    "    yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))\n",
    "    \n",
    "    out_scores, out_boxes, out_classes = yolo_eval(yolo_outputs, [image.size[1],  image.size[0]], 10, 0.3, 0.5)\n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), \"images/\" + image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = get_colors_for_classes(len(class_names))\n",
    "    # Draw bounding boxes on the image file\n",
    "    #draw_boxes2(image, out_scores, out_boxes, out_classes, class_names, colors, image_shape)\n",
    "    draw_boxes(image, out_boxes, out_classes, class_names, out_scores)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=100)\n",
    "    # Display the results in the notebook\n",
    "    output_image = Image.open(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "\n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "228997af-0b98-4073-b2eb-78fdf61085be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 boxes for images/test.jpg\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out_scores, out_boxes, out_classes \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(image_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m colors \u001b[38;5;241m=\u001b[39m get_colors_for_classes(\u001b[38;5;28mlen\u001b[39m(class_names))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes on the image file\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#draw_boxes2(image, out_scores, out_boxes, out_classes, class_names, colors, image_shape)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mdraw_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Save the predicted bounding box on the image\u001b[39;00m\n\u001b[1;32m     19\u001b[0m image\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_file), quality\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Car Detection with YOLO/yad2k/utils/utils.py:91\u001b[0m, in \u001b[0;36mdraw_boxes\u001b[0;34m(image, boxes, box_classes, class_names, scores)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Draw bounding boxes on image.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03mDraw bounding boxes with class name and optional box score on image.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    A copy of `image` modified with given bounding boxes.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#image = Image.fromarray(np.floor(image * 255 + 0.5).astype('uint8'))\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[43mImageFont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruetype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfont/FiraMono-Medium.otf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3e-2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m thickness \u001b[38;5;241m=\u001b[39m (image\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m image\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m     96\u001b[0m colors \u001b[38;5;241m=\u001b[39m get_colors_for_classes(\u001b[38;5;28mlen\u001b[39m(class_names))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/PIL/ImageFont.py:791\u001b[0m, in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfreetype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_path(font):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/PIL/ImageFont.py:788\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreetype\u001b[39m(font):\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFreeTypeFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/PIL/ImageFont.py:226\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 load_from_bytes(f)\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfont\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_engine\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     load_from_bytes(font)\n",
      "\u001b[0;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "out_scores, out_boxes, out_classes = predict(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be967a8-a81e-40ae-9e73-ff1a79c42209",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Summary for YOLO\n",
    "\n",
    "- Input image (608, 608, 3)\n",
    "- The input image goes through a CNN, resulting in a (19,19,5,85) dimensional output. \n",
    "- After flattening the last two dimensions, the output is a volume of shape (19, 19, 425):\n",
    "    - Each cell in a 19x19 grid over the input image gives 425 numbers. \n",
    "    - 425 = 5 x 85 because each cell contains predictions for 5 boxes, corresponding to 5 anchor boxes, as seen in lecture. \n",
    "    - 85 = 5 + 80 where 5 is because $(p_c, b_x, b_y, b_h, b_w)$ has 5 numbers, and 80 is the number of classes we'd like to detect\n",
    "- You then select only few boxes based on:\n",
    "    - Score-thresholding: throw away boxes that have detected a class with a score less than the threshold\n",
    "    - Non-max suppression: Compute the Intersection over Union and avoid selecting overlapping boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214b3cd-9b4f-47ef-a1a8-7e428bba3212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa6fdb-51e7-4be9-b4f1-9890f02814b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008beb5c-71ac-4ce8-b050-d4b59e38d7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877beaf8-c0ba-467e-81a3-57dae26474f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c5209-a3c2-401a-acc2-350aa4586a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
